---
title: "about"
date: 2020-10-20T17:51:47+03:30
draft: false
headless: true

full_name: "Stanley Z.Hua"
profile_picture: "profile.png"
cv: "cv.pdf"
# set to false if you don't want to show your blog
blog: true

socials:
    github: "stan-hua"
    linkedin: "stanley-z-hua"
    google_scholar: "citations?user=PNDkjjQAAAAJ&hl=en&authuser=1"

interests:
    - Robust Machine Learning
    - Transfer Learning
    - Self-Supervised Learning

affiliations:
    - affiliation:
        title: "Data Enthusiast"
        name: "Toronto, Ontario, CA"
        email: "stanley.z.hua@gmail.com"

academia:
    - course:
        degree: "B.Sc."
        institution:  "University of Toronto"
        major: "Computer Science Specialist, Statistics Minor"
        start_date: "2019"
        end_date: "2024 (Expected)"
---

**Hi!** My name is Stan, and I want to create machine learning models that generalize. 

I am particularly interested in methods that improve generalization when labeled data is scarce and noisy. In the past, I've explored:
1. Large domain-specific pre-training datasets for transfer learning with microscopy images
2. Supervised contrastive pre-training to improve generalization of ultrasound video models across hospitals
3. Large language models for automated soft-labeling of domain-specific text with prompt engineering

I am also a believer of [slow science](https://en.wikipedia.org/wiki/Slow_science) when possible.

Shoot me an email if you'd like to chat! And do include the word "stupefy" in your email.

