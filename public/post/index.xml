<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The Curiosity Box | Stanley Z. Hua</title>
    <link>https://stanhua.rbind.io/post/</link>
      <atom:link href="https://stanhua.rbind.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>The Curiosity Box</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 04 Jan 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://stanhua.rbind.io/img/me</url>
      <title>The Curiosity Box</title>
      <link>https://stanhua.rbind.io/post/</link>
    </image>
    
    <item>
      <title>PCA for Dimensionality Reduction</title>
      <link>https://stanhua.rbind.io/post/pca-part-i/pca_part_1/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://stanhua.rbind.io/post/pca-part-i/pca_part_1/</guid>
      <description>&lt;style&gt;
body {font-size: 80%}
.note{font-size: 10pt;
      line-height: 20pt;
      padding-bottom: 10px}
p{text-indent: 2em;}

details{font-size: 10pt;}
summary{font-size: 100% !important;}
&lt;/style&gt;
&lt;hr&gt;
&lt;h3&gt;OVERVIEW&lt;/h3&gt;
&lt;p&gt;Principle Component Analysis (PCA) is known for two things: 1) Dimensionality Reduction, and 2) Structure Analysis. Note that it can also be used for &lt;strong&gt;factor extraction&lt;/strong&gt;, the first step in Factor Analysis.&lt;/p&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;b&gt;NOTE&lt;/b&gt;: There are plenty of resources online if you wish to learn more about Factor Analysis, but they will not be covered here!
&lt;/div&gt;
&lt;h4&gt;TERMINOLOGY&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;High dimensionality&lt;/strong&gt; means that the data has a lot of variables. Think 1000+ column variables!&lt;/p&gt;
&lt;p&gt;The goal of &lt;strong&gt;Dimensionality Reduction&lt;/strong&gt; is to reduce the number of dimensions, while retaining as much useful information from the original data as possible.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Example and Enrichment&lt;/summary&gt;
&lt;p&gt;Say you wish to visualize your data, in order to get an understanding of the relationships between each feature. However, you have too many features. It becomes impossible to plot them on an x-y graph. How do you visualize this without destroying your computer let alone the laws of physics? You can reduce the number of dimensions to 2, then plot it on a coordinate plane! &lt;/p&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;b&gt;NOTE&lt;/b&gt;: Dimensionality Reduction is different from &lt;i&gt;Feature Selection&lt;/i&gt; (e.g. L1 Regularization, L2 Regularization, etc.). The goal of feature selection is to select the most important features. Meanwhile, dimensionality reduction is used to project high-dimensional data onto a set of low-dimensional features.
&lt;/div&gt;
&lt;/details&gt;
&lt;br&gt;
&lt;p&gt;Given p features, &lt;strong&gt;Principal Components&lt;/strong&gt; are the [1, min(n, p)] new variables extracted from n features using Principal Component Analysis. You can think of them as new axes to view the original data. &lt;em&gt;However, you can no longer interpret the principal components the same way you did with previous features&lt;/em&gt;.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Enrichment&lt;/summary&gt;
If you have 10 features and you transform them via PCA to get 10 principal components, they are not the same. If you previously had age and weight, now you simply have axes for data points with no interpretable meaning unlike the original variables. With PCA, you may end up with combinations of these variables. Tell me, is there meaning in a new variable that is 30% age and 70% weight?
&lt;/details&gt;
&lt;br&gt;&lt;br&gt;
&lt;h3&gt;GENERAL IDEA&lt;/h3&gt;
&lt;p&gt;To build intuition about what happens in Principal Component Analysis, let&amp;rsquo;s use the graph below as an example.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://stanhua.rbind.io/post/PCA-Part-I/2020-10-10-pca-for-dummies.en_files/figure-html/plot-1.png&#34; width=&#34;336&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here, we have 2 features. You can imagine each point representing an observation (e.g. one of your participants).&lt;/p&gt;
&lt;p&gt;When you implement PCA, imagine a line placed at the mean (of all the data points). Imagine rotating it, and every time that you rotate it, it changes how far each observation (i.e. its projection onto the line) point is from the center of the line. This is also called the &lt;strong&gt;squared distances&lt;/strong&gt;. And this is what we&amp;rsquo;re trying to &lt;em&gt;maximize&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;By doing so, it is as if we are trying to find a line where the observations are farthest from center. Thus, we capture the most amount of variation along this line, and this line is known as a principal component!&lt;/p&gt;
&lt;p&gt;Once again, notice how the features no longer have anything to do with the new axes (principal component). Also notice that if you had 3 or more features, graphing it like we did is no longer possible.&lt;/p&gt;
&lt;h3 id=&#34;example-code&#34;&gt;Example Code&lt;/h3&gt;
&lt;p&gt;We provide a brief example of how to perform PCA on your data in Python. 
Be aware of a few things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;When you have less rows (observations) than columns (variables), you can at most have the number of dimensions as the number of rows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For intuition, we can only fit at most m different lines through those m data points (observations).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your variables are scaled differently, it is advisable to standardize your data first.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each column may be standardized to have a mean of 0 and standard deviation of 1.&lt;/li&gt;
&lt;li&gt;e.g. column A has values greater than 10,000, while column B has values around 50.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;import pandas as pd
from sklearn.decomposition import PCA


def reduce_dim(X, dims=2) -&amp;gt; pd.DataFrame:
    &amp;quot;&amp;quot;&amp;quot;
    Given a dataframe with n variables and m rows, perform PCA
    and project X to reduce the dimensionality.
    
    Parameters
    ----------
    X : pd.Dataframe or array-like
      A table of (n columns x m rows).
    dims: int
      The desired number of variables (i.e. dimensionality)
      after transforming &amp;lt;X&amp;gt;.
    
    Returns
    -------
    pd.DataFrame
      The input X projected onto (&amp;lt;dims&amp;gt; columns x m rows).
    &amp;quot;&amp;quot;&amp;quot;
    pca = PCA(n_components=dims)
    X_transformed = pd.DataFrame(pca.fit_transform(X))
    return X_transformed
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Thanks for reading!&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;Additional Resources&lt;/h3&gt;
&lt;p&gt;StatQuest has great videos explaining what I mentioned with the graph with more detail! (&lt;a href=&#34;https://www.youtube.com/watch?v=FgakZw6K1QQ&#34;&gt;https://www.youtube.com/watch?v=FgakZw6K1QQ&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Dimensionality Reduction</title>
      <link>https://stanhua.rbind.io/post/intro-dim-red/intro_to_dimred/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://stanhua.rbind.io/post/intro-dim-red/intro_to_dimred/</guid>
      <description>


&lt;style&gt;
h1{font-size: 165%;}
body {font-size: 80%}
.note{font-size: 10pt;
      line-height: 20pt;
      padding-bottom: 10px}
p{text-indent: 2em;}
details{font-size: 10pt;}
summary{font-size: 100% !important;}
&lt;/style&gt;
&lt;p&gt;Imagine a newly-founded insurance company collects data on their customers (e.g. their sex, age, occupation, location). With this information, the company would like to group their customers, in order to ascertain who are more likely to have risks to their health. To make a profit, the executives believe that customers in high-risk groups should be charged more expensive premiums. They decide to outsource this problem to you. Now, you are given a table with 100,000 customers and 1000 different column variables. What do you do?&lt;/p&gt;
&lt;p&gt;If you’re stubborn, you can try to compare all 1000 variables for all 100,000 customers, but this is an impossible task, possibly even for a machine. There are simply way too many &lt;em&gt;dimensions&lt;/em&gt; or variables to look at. What if you could inspect 2 or 3 variables instead? Though still a Herculean task for any human, it’s far more reasonable to compare two numbers than 1000.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;This brings us to the &lt;strong&gt;Curse of Dimensionality&lt;/strong&gt;, which tells us that as the number of dimensions in our data increase, the distance between our data points are going to become equal. This is important! Most methods of grouping people (or clustering data points) is based on &lt;em&gt;Euclidean&lt;/em&gt; distance between points. Intuitively, this is to say that the customers cannot be differentiated from one another, so how do you cluster them into groups?&lt;/p&gt;
&lt;p&gt;Generally, there are two ways you could &lt;strong&gt;&lt;em&gt;reduce&lt;/em&gt;&lt;/strong&gt; the &lt;strong&gt;&lt;em&gt;dimensionality&lt;/em&gt;&lt;/strong&gt; of your data. You can either select the top n number of most impactful variables related to health risk, such as age and occupation. Or you could represent those variables in another way. I am referring to 1) Feature Selection, and 2) Dimensionality Reduction. Make no mistake. They are very different methods!&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Enrichment&lt;/summary&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;p&gt;&lt;b&gt;NOTE&lt;/b&gt;: The &lt;em&gt;new&lt;/em&gt; variables are combinations of the old variables. They will have no interpretable meaning. In feature selection, you’re simply keeping some variables and dropping the rest. Those variables retain their meaning!&lt;/p&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The one I will be discussing soon is &lt;strong&gt;Dimensionality Reduction&lt;/strong&gt;. The goal of which is to &lt;strong&gt;&lt;em&gt;represent&lt;/em&gt;&lt;/strong&gt; as much &lt;strong&gt;&lt;em&gt;useful&lt;/em&gt;&lt;/strong&gt; information in your data with the fewest number of dimensions.&lt;/p&gt;
&lt;p&gt;Imagine all the useful information about your participants could be represented with one or more &lt;em&gt;new&lt;/em&gt; variables that can explain almost as much as those 1000 variables. That is the essence of dimensionality reduction! Now, you can proceed with grouping the company’s customers.&lt;/p&gt;
&lt;p&gt;In the next post, we will focus on building intuition for Principal Component Analysis, a frequently used dimensionality reduction method. See you there!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Connecting to a remote server</title>
      <link>https://stanhua.rbind.io/post/remote-server/connecting-to-remote-servers-via-ssfhs-ssh/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://stanhua.rbind.io/post/remote-server/connecting-to-remote-servers-via-ssfhs-ssh/</guid>
      <description>&lt;style&gt;
.note{font-size: 10pt;
      line-height: 20pt;
      padding-bottom: 10px}
p{text-indent: 2em;}

details{font-size: 10pt;}
summary{font-size: 100% !important;}
&lt;/style&gt;
&lt;p&gt;Working from home?&lt;/p&gt;
&lt;p&gt;You might be one of us who need to connect to a remote server from home. Now, how do you do this? Maybe it&amp;rsquo;s better to ask first what is your operating system (e.g. Windows, MacOS, etc.).&lt;/p&gt;
&lt;p&gt;This post will show you 1) how to connect to a remote server on Windows, AND 2) how to &lt;sup&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/sup&gt;mount the server on your computer on Windows and Debian.&lt;/p&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;b&gt;NOTE&lt;/b&gt;: This blog post assumes you know basic Unix commands. If not, I recommend learning some of the basics, then come back when you&#39;re done!
&lt;/div&gt;
&lt;hr&gt;
&lt;h3 id=&#34;1-simple-access-to-server-files-via-ssh-secure-shell&#34;&gt;1. Simple access to server files via ssh (Secure Shell)&lt;/h3&gt;
&lt;p&gt;
Before you start, you&#39;ll most likely be needing 3 things: 1) the &lt;b&gt;username&lt;/b&gt; of your server account, 2) the server &lt;b&gt;IP adress&lt;/b&gt;, and 3) the password associated with the server account if applicable. Okay, now open your command prompt via cmd.exe. Your command prompt command should generally follow what is displayed below.
&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...&amp;gt; ssh username@125.950.26.789
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The command is &amp;ldquo;ssh&amp;rdquo; followed by your server username, &amp;ldquo;@&amp;rdquo;, and the server ip address. After which, you may be prompted by the console to input your password. After doing so, you should be connected. Congratulations!&lt;/p&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;b&gt;NOTE&lt;/b&gt;: This connection is temporary and will be gone once you exit the command prompt, or when your machine is powered off or loses connection to the internet. If so, you will need to enter the command again.
&lt;/div&gt;
&lt;p&gt;Soon enough, you&amp;rsquo;ll realize the pain of having to do this every time you close the command prompt. Another option is to mount the server files. Then you&amp;rsquo;ll be able to view the files on your machine as if they were just any files on your desktop!&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;2-mounting-server-files-via-sshfs&#34;&gt;2. Mounting server files via sshfs&lt;/h3&gt;
&lt;p&gt;SSHFS is Linux-based and doesn&amp;rsquo;t come installed. See below on how to install it, and the command to mount server files on your computer.&lt;/p&gt;
&lt;h4 id=&#34;on-windows&#34;&gt;On Windows&lt;/h4&gt;
&lt;p&gt;First, download and install google&amp;rsquo;s latest win-sshfs package by clicking &lt;a href=&#34;https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/win-sshfs/win-sshfs-0.0.1.5-setup.exe&#34;&gt;here&lt;/a&gt;. After doing this, you can simply input the following into your command line.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;net use \\sshfs\username@ip_address//            #// brings you to your home dir. in the server


##More examples
#To connect at specific file path
net use \\sshfs\username@ip_address//file-path
net use \\sshfs\username@ip_address//Users\Stanley\Desktop

#To enter password with command
net use \\sshfs\username@ip_address//file-path /user:username password    #space between file path and /user: argument
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;b&gt;NOTE&lt;/b&gt;: &lt;i&gt;&#34;net use&#34;&lt;/i&gt; is used to map network drives to your computer.
&lt;/div&gt;
&lt;h4 id=&#34;on-debian&#34;&gt;On Debian&lt;/h4&gt;
&lt;p&gt;Similar to Windows, you have to install sshfs for Debian, but this can all be done in the terminal! Follow the steps below to install, then mount the remote server on your machine&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#Install SSHFS
sudo apt-get install sshfs

#OPT: Create directory to mount server files on
sudo mkdir /mnt/droplet

#Mount
sudo sshfs -o allow_other,default_permissions username@ip_address:/file_path /mnt/droplet
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;b&gt;NOTE&lt;/b&gt;: Be careful of spaces!
&lt;/div&gt;
&lt;hr&gt;
&lt;h3 id=&#34;additional-resources&#34;&gt;Additional Resources&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-use-sshfs-to-mount-remote-file-systems-over-ssh&#34; target=&#34;_blank&#34;&gt;SSHFS Mounting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;sup&gt;&lt;b&gt;1&lt;/sup&gt;Mount&lt;/b&gt; ::= having the remote server&#39;s files on your local machine, accessible by file explorer.
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Save the Pandas...library</title>
      <link>https://stanhua.rbind.io/post/pandas/useful_commands_to_remember/</link>
      <pubDate>Sat, 11 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://stanhua.rbind.io/post/pandas/useful_commands_to_remember/</guid>
      <description>


&lt;style&gt;
body {font-size: 10pt}
h2{
  text-decoration: underline;
  line-height: 5pt;
  text-align: center;
  padding-top: 30px;
}
&lt;/style&gt;
&lt;p&gt;By convention, “&lt;strong&gt;&lt;em&gt;df&lt;/em&gt;&lt;/strong&gt;” will refer to a dataframe object, while “&lt;strong&gt;&lt;em&gt;Series&lt;/em&gt;&lt;/strong&gt;” will refer to a series object.&lt;/p&gt;
&lt;hr /&gt;
&lt;!-- ### --&gt;
&lt;!-- ``` --&gt;
&lt;!-- ``` --&gt;
&lt;!-- &lt;br&gt; --&gt;
&lt;div id=&#34;importing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Importing&lt;/h2&gt;
&lt;div id=&#34;importing-the-libraries&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Importing the Libraries&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd
import numpy as np        #NumPy library required by Pandas library&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;read-csv-file-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Read csv file data&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df = pd.read_csv(file_path, index_col=None)&lt;/code&gt;&lt;/pre&gt;
&lt;!-- ################################################################ --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;about-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;About dataset&lt;/h2&gt;
&lt;div id=&#34;check-column-names&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Check column names&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.columns

Series.name&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;check-shape-of-object&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Check shape of object&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.shape

Series.shape&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;columns-of-a-specific-data-type-type&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Columns of a specific data type type&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.dtypes == &amp;#39;object&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;describe-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Describe data&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.describe()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;unique-vs-nunique&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Unique vs Nunique&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;for col in df.columns:    # for loop to get column names
  df[col].unique()            # returns unique values in column &amp;#39;col&amp;#39;
  df[col].nunique()           # returns unique values in column AND drop NAs&lt;/code&gt;&lt;/pre&gt;
&lt;!-- ################################################################ --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;slicing-and-filtering&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Slicing and Filtering&lt;/h2&gt;
&lt;div id=&#34;filter&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Filter&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.filter(items=, like=None)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;iloc&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html&#34; target=&#34;_blank&#34;&gt;Iloc &lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.iloc[row_position, col_position]    # general format&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&#34;note&#34;&gt;
COPY of dataframe is slice is returned. This CANNOT be used in assignment. Also, note that only integers, its derivations and boolean arrays can be used to index.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;loc&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html&#34; target=&#34;_blank&#34;&gt;Loc&lt;/a&gt;&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;index = (df.Color==&amp;quot;Red&amp;quot;) &amp;amp; (df.Item==&amp;quot;Shirt&amp;quot;)        # produces a boolean array
df.loc[index]        # returns original dataframe sliced


df.loc[row_indexer, col_indexer]        #general format&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&#34;note&#34;&gt;
&lt;b&gt;Note&lt;/b&gt;: colon “:” is not needed by col_indexer like in &lt;em&gt;df.loc[index, :]&lt;/em&gt; to choose all columns, and slice of ORIGINAL dataframe is returned. This can be used for assignment.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;query-columns&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Query (columns)&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.query(&amp;#39;expression&amp;#39;)    # expression must be conditional using column variable/s
                          # prefix &amp;quot;@&amp;quot; before variable name if outside of dataframe env.
                          # prefix ` ` to encapsulate variable name with spaces&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&#34;note&#34;&gt;
Can be used to filter rows.
&lt;/p&gt;
&lt;!-- ################################################################ --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Processing&lt;/h2&gt;
&lt;div id=&#34;apply-a-function-on-a-pandas-object&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Apply (a function on a pandas object)&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.apply(FUN, axis=0, *args)    # FUN: any (valid) function to apply
                                # axis: axis to assess
                                # *args: additional keyword arguments for FUN&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;assign-new-columns&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Assign (new columns)&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.assign(col_4 = col_1*col_2/col_3)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&#34;note&#34;&gt;
Used to create new columns. Similar to “mutate” in R.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;get-dummies-one-hot-encoding&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Get Dummies (One Hot Encoding)&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.get_dummies(dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=np.uint8)
        # dummy_na: if True, adds dummy column for NA
        # columns: if !None, columns specified will be one hot encoded
        # sparse: whether resulting columns will be SparseArray objects (True) or NumPy arrays(False) 
        # drop_first: removes first unique dummy variable from unique objects in column
        # dtype: data type for new columns (e.g. float)


Series.get_dummies(dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=&amp;#39;np.uint8&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;group-by-then-transform&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Group by, then Transform&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.groupby(by=category).transform(FUN)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;p&gt;Grouping a dataframe then transforming it is a very common operation. A dataframe is converted into a “GroupBy” object depending on &lt;em&gt;category&lt;/em&gt;, which may be a string or list of strings representing column names. Then the resulting object’s values are passed into &lt;em&gt;FUN&lt;/em&gt; by the transform function and a column of the same size is returned.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;handling-na&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Handling NA&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#Finding NA and inverse
df.isna()
Series.isna()

df.notna()
Series.isna()


#Dropping NA
df.dropna(axis=0, how=&amp;#39;any&amp;#39;, thresh=None, subset=None, inplace=False)
        # axis: axis to assess
        # how: when to drop axis (e.g. how=&amp;#39;all&amp;#39; drops IFF all values are NA)
        # thresh: number of NAs in axis to drop
        # subset: labels on axis to be considered
        # inplace: by default, returns new object. If True, modifies existing object
        
Series.dropna(axis=0, how=None,inplace=False)


#Filling NA
df.fillna(value=None, method=None, axis=None, inplace=False, limit=None)
        # value: value to fill holes
        # method: method for filling holes.*
        # inplace: by default, returns new object. If True, modifies existing object
        # limit: max number of consecutive NAs to fill. Will be left as NA if value is exceeded

Series.fillna(value=None, method=None, axis=None, inplace=False, limit=None)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mapping&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Mapping&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.applymap(FUN)
Series.map(FUN)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&#34;note&#34;&gt;
Iterates by rows (for Series) and cell (for DataFrame), passing cell value into function with the output value replacing its input value.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;piping-data-through-multiple-functions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Piping Data (through multiple functions)&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.pipe(FUN1).pipe(FUN2, arg1=foo).pipe((FUN3, &amp;quot;arg2&amp;quot;), arg1=bar)        
    # when FUN3&amp;#39;s main arg. is not df, supply tuple
      where str contains location for df (e.g. &amp;quot;arg2&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p class=&#34;note&#34;&gt;
&lt;b&gt;NOTE&lt;/b&gt;: similar to %&amp;gt;% operation in R.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rolling&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Rolling&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;df.rolling(num_observations).FUN()
Series.rolling(num_observations).FUN()


# Example of counting observations every 7 days past
Series.rolling(&amp;#39;7d&amp;#39;).count()-1        # subtraction excludes day &lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;p&gt;This is similar to GroupBy then Transform, but function is applied to “rolls” going down a specific column/index.&lt;/p&gt;
&lt;/div&gt;
&lt;!-- ### --&gt;
&lt;!-- ``` --&gt;
&lt;!-- ``` --&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-resources&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Additional Resources&lt;/h3&gt;
&lt;p class=&#34;note&#34;&gt;
A great resource for comparing df.&lt;strong&gt;agg&lt;/strong&gt;(), df.&lt;strong&gt;apply&lt;/strong&gt;(), df.&lt;strong&gt;applymap&lt;/strong&gt;() and df.&lt;strong&gt;transform&lt;/strong&gt;() can be found &lt;a href=&#34;https://stackoverflow.com/questions/46210678/whats-the-difference-between-transform-vs-applymap-for-pandas-dataframe&#34;&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Monte Carlo Simulations</title>
      <link>https://stanhua.rbind.io/post/monte-carlo-simulations/monte-carlo-simulations/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://stanhua.rbind.io/post/monte-carlo-simulations/monte-carlo-simulations/</guid>
      <description>


&lt;style&gt;
.note{font-size: 10pt;
      line-height: 20pt;
      padding-bottom: 10px}
p{text-indent: 2em;}
details{font-size: 10pt;}
summary{font-size: 100% !important;}
&lt;/style&gt;
&lt;details&gt;
&lt;summary&gt;
Trying to simulate a random event? Then you’ve come to the right place!
&lt;/summary&gt;
&lt;p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you do not have true proportion or estimated probabilities for your simulation, then this may not help you!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;hr /&gt;
&lt;div id=&#34;premise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Premise&lt;/h3&gt;
&lt;p&gt;Say you want to understand how randomness works, and you want to roll a 12-sided die and see how many times it lands on 1. You’ll do roll a die 100, 10,000, 1,000,000 times.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/strong&gt; Every side of the die has a probability of 1/12, but the outcome of each roll is random and independent from one another.
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-0-set-the-seed-to-some-arbitrary-constant.-optional&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;strong&gt;Step 0:&lt;/strong&gt; Set the seed to some arbitrary constant. (Optional)&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2009, sample.kind=&amp;quot;Rounding&amp;quot;)    #for R 3.6 and later

set.seed(2009)                            #for 3.5 and older&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you wish to observe the same results for lower numbers of draws, you can place this at the start of your script.
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-1-construct-a-method-for-sampling.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Construct a method for sampling.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Ns = c(100, 10000, 1000000)                                          #number of simulations

simulations &amp;lt;- sapply(Ns, function(N){
  sim &amp;lt;- sample(c(1, -1), N, replace=TRUE, prob=c(1/12, 11/12))   #sampling
  mean(sim == 1)                                                  #find the proportion of rolls which are 1 (success)
})&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Sample.Size&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Proportion.Observed&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1e+02&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.070000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1e+04&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.077900&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1e+06&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.083293&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The sample function takes N rolls (with replacement). The result can either be 1; a success (landing on 1), or -1; a failure (not landing on one). The keyword argument “prob” defines the probability for possible events success or failure.&lt;/p&gt;
&lt;p&gt;As you can see from the results, the &lt;strong&gt;&lt;em&gt;proportion&lt;/em&gt;&lt;/strong&gt; of rolls landing on 1 converges to the probability we defined it to be (1/12 = 0.0833), as the &lt;strong&gt;&lt;em&gt;number&lt;/em&gt;&lt;/strong&gt; of rolls increases.&lt;/p&gt;
&lt;br&gt;
&lt;h3&gt;
For Understanding
&lt;/h3&gt;
&lt;p&gt;To close, it may be good to point out a common misconception when it comes to expectation. Say if you and your friends are tossing a coin and it lands on heads, you might be tempted to say “The next one will be tails!”, but that’s wrong. We know logically that the probability of either side landing is 1/2, but we would only be able to observe this when we sum up the results of maybe a thousand or hundred thousand rolls, as we have just done.
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;Law of Large Numbers&lt;/em&gt; (or &lt;em&gt;the Law of Averages&lt;/em&gt;) states that as the number of draws (rolls) increases, the standard error (standard deviation but for samples) of the expected value approaches 0. In which case, the expected value converges to the probability we defined.
&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;
Enrichment
&lt;/h3&gt;
&lt;p&gt;You can try to compute for the standard error for each simulation using the formula:&lt;/p&gt;
&lt;div class=&#34;note&#34;&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(SE[\overline{X}]=|b-a|*\frac{\sqrt{p(1-p)}}{N}\)&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;line-block&#34;&gt;    where SE means standard error;&lt;br /&gt;
                X_bar is the sample random variable;&lt;br /&gt;
                a and b are the values we attribute to success and failure (i.e. 1 and -1);&lt;br /&gt;
                p is the probability of success (i.e. 1/12);&lt;br /&gt;
                and N is the sample size.&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: For cases wherein the probability is not defined, we can use the &lt;code&gt;replicate&lt;/code&gt; function that takes two arguments. The second argument defines a line or set of lines to replicate, while the first argument is the number of times you wish to repeat the second argument.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;: Creating a list of sample means.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;array                           # a non-empty numeric array of length 100,000
B &amp;lt;- 1000                       # number of replications
N &amp;lt;- 100                        # number of samples
sample_means &amp;lt;- replicate(B, {
    sample_array &amp;lt;- sample(array, N, replace=TRUE)
    mean(sample_array)          #like a function; this is returned
})
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A First</title>
      <link>https://stanhua.rbind.io/post/first/a-first/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://stanhua.rbind.io/post/first/a-first/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;Here lies my first blog post.&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
