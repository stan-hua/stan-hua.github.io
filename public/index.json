[{"authors":["admin"],"categories":null,"content":"\r.smaller{\rfont-size: 70%;\r}\r.libraries{\rfont-size: 90%;\r}\r\rAspiring to become an industry data scientist, I am passionate about using data science tools to answer questions. I strongly value mentorship, and I enjoy the process of explaining concepts in a way that is easy for my listener to understand.\nPreviously a premed, my research experience with Prof. Pascal Tyrrell truly sparked my interest in the use of data science to create an impact. Here, I learnt about the problems that arise for statistical and deep learning models when there are too few data samples. My project focused on improving a methodology for capturing the effect of dataset heterogeneity (from small sample sizes) on CNN model training. Specifically, I focused on the effects of decisions made in the dimensionality reduction step (PCA) before cluster analysis.\nOn the other hand, my time with Prof. Alan Moses and Dr. Alex Lu taught me about the challenges of handling vast amounts of unstardardized image data. Under their expertise, I curated and trained models on CytoImageNet, a large-scale dataset of openly-sourced microscopy image data in the hopes of providing biologists a fast and automatic means for extracting biologically-relevant information from their images.\nThese experiences have deepened my appreciation for the data collection, storage and preprocessing pipelines that occur before modeling.\nPersonally, I find it beautiful how a plethora of sophisticated tools come together in harmony to create a potentially simple yet impactful story.\n LANGUAGES: [Python, R, Shell Script, SQL, HTML, CSS, MATLAB]\nPython Libraries: [pandas, dask, numpy, matplotlib, tensorflow, keras, pytorch, sklearn, xgboost, lightgbm, PIL, cv2,]\nR Libraries: [rvest, ggplot2, tidyverse, dplyr, blogdown, knitr, shiny, flexdashboard]\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/stanley-z.-hua/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/stanley-z.-hua/","section":"authors","summary":".smaller{\rfont-size: 70%;\r}\r.libraries{\rfont-size: 90%;\r}\r\rAspiring to become an industry data scientist, I am passionate about using data science tools to answer questions. I strongly value mentorship, and I enjoy the process of explaining concepts in a way that is easy for my listener to understand.","tags":null,"title":"Stanley Z. Hua","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bb560906b6a99893cc21387348c0b074","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"7e3f612f965abd2710b4c960da39ef69","permalink":"/project/cytoimagenet/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/project/cytoimagenet/","section":"project","summary":"Curated a large-scale dataset of openly-sourced microscopy images to use in pretraining convolutional neural networks. The goal is to provide biologists a convenient and fast means to extract biologically-meaningful image features from their images.","tags":["In Progress"],"title":"CytoImageNet for Bioimage Transfer Learning","type":"project"},{"authors":null,"categories":null,"content":"","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"0f4aab6db4ce898aeecadca929e52d76","permalink":"/project/cluster-analysis/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/project/cluster-analysis/","section":"project","summary":"Demonstrated that a recently proposed algorithm (*to describe the effect of heterogeneity on model training*) is impacted by the numbers of principal components used in the cluster analysis. Proposed a new method for selecting the number of dimensions to keep..","tags":["Completed"],"title":"Dataset Heterogeneity on CNN Model Training","type":"project"},{"authors":null,"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"73e4295b78a6db4393008f4dcfb7387d","permalink":"/project/ranzcr-clip/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/project/ranzcr-clip/","section":"project","summary":"Trained a multi-label classifier to determine correct/incorrect placement of catheter line in chest x-ray images. Achieved an AUC of 0.864; scoring higher than 180 teams.","tags":["Completed"],"title":"Kaggle RANZCR-CLiP Challenge","type":"project"},{"authors":[],"categories":[],"content":"\rbody {font-size: 80%}\r.note{font-size: 10pt;\rline-height: 20pt;\rpadding-bottom: 10px}\rp{text-indent: 2em;}\rdetails{font-size: 10pt;}\rsummary{font-size: 100% !important;}\r\rDISCLAIMER: This is an introduction into PCA and does not go into depth on the statistics or code. Tread carefully! \r OVERVIEW\rPrinciple Component Analysis (PCA) is known for two things: 1) Dimensionality Reduction, and 2) Structure Analysis. Note that it can also be used for factor extraction, the first step in Factor Analysis.\nNOTE: There are plenty of resources online if you wish to learn more about Factor Analysis, but they will not be covered here!\r\rTERMINOLOGY\rSo as not to lose anyone, let\u0026rsquo;s define some useful terminology! Features are what we are measuring.\n\rExample\rSay we have a table with y rows and x columns, then we have x features. Imagine each row being the names of someone you know, and each column measure something distinct about all persons listed (e.g. their height, weight, deepest darkest secrets, etc.). These things we're measuring are the features.\n\rDimensionality Reduction is exactly what it sounds like. The goal is to reduce the number of dimensions (i.e. number of features), while retaining useful information from the original data.\n\rExample and Enrichment\rSay you wish to visualize your data, in order to get an understanding of the relationships between each feature. However, you have too many features. It becomes impossible to plot them on an x-y graph. How do you visualize this without destroying your computer let alone the laws of physics? Simple, you reduce the number of dimensions to 2. Now, you can plot it on a coordinate plane! NOTE: Dimensionality Reduction is different from Feature Selection (e.g. L1 Regularization, L2 Regularization, etc.). The goal of feature selection is to select the most important features. Meanwhile, dimensionality reduction is used to lessen the number of dimensions while capturing the variation in the original data as much as possible.\r\r\rGiven p features, Principal Components are the [1, min(n, p)] new variables extracted from n features using Principal Component Analysis. You can think of them as new axes to view the original data. However, you can no longer interpret the principal components the same way you did with previous features.\n\rEnrichment\rIf you have 10 features and you transform them via PCA to get 10 principal components, they are not the same. If you previously had age and weight, now you simply have axes for data points with no interpretable meaning unlike the original variables. With PCA, you may end up with combinations of these variables. Tell me, is there meaning in a new variable that is 30% age and 70% weight?\r\rGENERAL IDEA\rTo build intuition about what happens in Principal Component Analysis, let\u0026rsquo;s use the graph below as an example.\nHere, we have 2 features. You can imagine each point representing an observation (e.g. one of your participants).\nWhen you implement PCA, imagine a line placed at the mean (of all the data points). Imagine rotating it, and every time that you rotate it, it changes how far each observation (i.e. its projection onto the line) point is from the center of the line. This is also called the squared distances. And this is what we\u0026rsquo;re trying to maximize.\nBy doing so, it is as if we are trying to find a line where the observations are farthest from center. Thus, we capture the most amount of variation along this line, and this line is known as a principal component!\nOnce again, notice how the features no longer have anything to do with the new axes (principal component). Also notice that if you had 3 or more features, graphing it like we did is no longer possible.\nIn Part II, we will explore how to do PCA in Python. See you there!\nAdditional Resources\rStatQuest has great videos explaining what I mentioned with the graph with more detail!\n","date":1609718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609631971,"objectID":"a1bf74a120c588e206bf89d8d1a30d34","permalink":"/post/pca-part-i/pca_part_1/","publishdate":"2021-01-04T00:00:00Z","relpermalink":"/post/pca-part-i/pca_part_1/","section":"post","summary":"Here is a brief overview on Principal Component Analysis, one of the most popular methods of dimensionality reduction today!","tags":["Data Science"],"title":"PCA Part I. Intuition","type":"post"},{"authors":[],"categories":[],"content":"\r\rh1{font-size: 165%;}\rbody {font-size: 80%}\r.note{font-size: 10pt;\rline-height: 20pt;\rpadding-bottom: 10px}\rp{text-indent: 2em;}\rdetails{font-size: 10pt;}\rsummary{font-size: 100% !important;}\r\rImagine a newly-founded insurance company collects data on their customers (e.g. their sex, age, occupation, location). With this information, the company would like to group their customers, in order to ascertain who are more likely to have risks to their health. To make a profit, the executives believe that customers in high-risk groups should be charged more expensive premiums. They decide to outsource this problem to you. Now, you are given a table with 100,000 customers and 1000 different column variables. What do you do?\nIf you’re stubborn, you can try to compare all 1000 variables for all 100,000 customers, but this is an impossible task, possibly even for a machine. There are simply way too many dimensions or variables to look at. What if you could inspect 2 or 3 variables instead? Though still a Herculean task for any human, it’s far more reasonable to compare two numbers than 1000.\nThis brings us to the Curse of Dimensionality, which tells us that as the number of dimensions in our data increase, the distance between our data points are going to become equal. This is important! Most methods of grouping people (or clustering data points) is based on Euclidean distance between points. Intuitively, this is to say that the customers cannot be differentiated from one another, so how do you cluster them into groups?\nGenerally, there are two ways you could reduce the dimensionality of your data. You can either select the top n number of most impactful variables related to health risk, such as age and occupation. Or you could represent those variables in another way. I am referring to 1) Feature Selection, and 2) Dimensionality Reduction. Make no mistake. They are very different methods!\n\rEnrichment\rNOTE: The new variables are combinations of the old variables. They will have no interpretable meaning. In feature selection, you’re simply keeping some variables and dropping the rest. Those variables retain their meaning!\n\r\r\nThe one I will be discussing soon is Dimensionality Reduction. The goal of which is to represent as much useful information in your data with the fewest number of dimensions.\nImagine all the useful information about your participants could be represented with one or more new variables that can explain almost as much as those 1000 variables. That is the essence of dimensionality reduction! Now, you can proceed with grouping the company’s customers.\nIn the next post, we will focus on building intuition for Principal Component Analysis, a frequently used dimensionality reduction method. See you there!\n","date":1609545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609647884,"objectID":"0d38911d3724d117d49effeb16a3c5f8","permalink":"/post/intro-dim-red/intro_to_dimred/","publishdate":"2021-01-02T00:00:00Z","relpermalink":"/post/intro-dim-red/intro_to_dimred/","section":"post","summary":"A quick briefer on the use of Dimensionality Reduction!","tags":["Data Science"],"title":"Intro to Dimensionality Reduction","type":"post"},{"authors":null,"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"1d3c9750db7b236baa2874bf31bd603f","permalink":"/project/ms-vasculitis/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/project/ms-vasculitis/","section":"project","summary":"Contributing towards creating a model that can discriminate between Multiple Sclerosis and Vasculitis in children, using structural T1 MRI images of the brain. Handling data preparation and cleaning, and assisting in model building.","tags":["In Progress"],"title":"Multiple Sclerosis vs. Vasculitis","type":"project"},{"authors":null,"categories":null,"content":"","date":1598400000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598400000,"objectID":"8144ea5cf58f638e30e75be4a48f47d2","permalink":"/project/recipe_scraper/","publishdate":"2020-08-26T00:00:00Z","relpermalink":"/project/recipe_scraper/","section":"project","summary":"A simple tool that scrapes recipe instructions from AllRecipes and places it in a simple recipe format. Made with R, shiny, flexdashboard, and shinyapps.io","tags":["Completed"],"title":"Recipe Scraper","type":"project"},{"authors":[],"categories":["Others"],"content":"\r.note{font-size: 10pt;\rline-height: 20pt;\rpadding-bottom: 10px}\rp{text-indent: 2em;}\rdetails{font-size: 10pt;}\rsummary{font-size: 100% !important;}\r\rWorking from home?\nYou might be one of us who need to connect to a remote server from home. Now, how do you do this? Maybe it\u0026rsquo;s better to ask first what is your operating system (e.g. Windows, MacOS, etc.).\nThis post will show you 1) how to connect to a remote server on Windows, AND 2) how to 1mount the server on your computer on Windows and Debian.\nNOTE: This blog post assumes you know basic Unix commands. If not, I recommend learning some of the basics, then come back when you're done!\r\r 1. Simple access to server files via ssh (Secure Shell) \rBefore you start, you'll most likely be needing 3 things: 1) the username of your server account, 2) the server IP adress, and 3) the password associated with the server account if applicable. Okay, now open your command prompt via cmd.exe. Your command prompt command should generally follow what is displayed below.\r...\u0026gt; ssh username@125.950.26.789\r The command is \u0026ldquo;ssh\u0026rdquo; followed by your server username, \u0026ldquo;@\u0026rdquo;, and the server ip address. After which, you may be prompted by the console to input your password. After doing so, you should be connected. Congratulations!\nNOTE: This connection is temporary and will be gone once you exit the command prompt, or when your machine is powered off or loses connection to the internet. If so, you will need to enter the command again.\r\rSoon enough, you\u0026rsquo;ll realize the pain of having to do this every time you close the command prompt. Another option is to mount the server files. Then you\u0026rsquo;ll be able to view the files on your machine as if they were just any files on your desktop!\n2. Mounting server files via sshfs SSHFS is Linux-based and doesn\u0026rsquo;t come installed. See below on how to install it, and the command to mount server files on your computer.\nOn Windows First, download and install google\u0026rsquo;s latest win-sshfs package by clicking here. After doing this, you can simply input the following into your command line.\nnet use \\\\sshfs\\username@ip_address// #// brings you to your home dir. in the server\r##More examples\r#To connect at specific file path\rnet use \\\\sshfs\\username@ip_address//file-path\rnet use \\\\sshfs\\username@ip_address//Users\\Stanley\\Desktop\r#To enter password with command\rnet use \\\\sshfs\\username@ip_address//file-path /user:username password #space between file path and /user: argument\r NOTE: \"net use\" is used to map network drives to your computer.\r\rOn Debian Similar to Windows, you have to install sshfs for Debian, but this can all be done in the terminal! Follow the steps below to install, then mount the remote server on your machine\u0026hellip;\n#Install SSHFS\rsudo apt-get install sshfs\r#OPT: Create directory to mount server files on\rsudo mkdir /mnt/droplet\r#Mount\rsudo sshfs -o allow_other,default_permissions username@ip_address:/file_path /mnt/droplet\r NOTE: Be careful of spaces!\r\r Additional Resources  SSHFS Mounting  1Mount ::= having the remote server's files on your local machine, accessible by file explorer.\r","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596326400,"objectID":"19740685cb881b481a6a828b96ca6c74","permalink":"/post/remote-server/connecting-to-remote-servers-via-ssfhs-ssh/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/post/remote-server/connecting-to-remote-servers-via-ssfhs-ssh/","section":"post","summary":"Adapting to remote work, learn quickly how to connect to a remote server from home using SSH and SSHFS!","tags":["Other"],"title":"Connecting to a remote server","type":"post"},{"authors":[],"categories":["Python"],"content":"\r\rbody {font-size: 10pt}\rh2{\rtext-decoration: underline;\rline-height: 5pt;\rtext-align: center;\rpadding-top: 30px;\r}\r\rBy convention, “df” will refer to a dataframe object, while “Series” will refer to a series object.\nImporting\rImporting the Libraries\rimport pandas as pd\rimport numpy as np #NumPy library required by Pandas library\r\rRead csv file data\rdf = pd.read_csv(file_path, index_col=None)\r\r\rAbout dataset\rCheck column names\rdf.columns\rSeries.name\r\rCheck shape of object\rdf.shape\rSeries.shape\r\rColumns of a specific data type type\rdf.dtypes == \u0026#39;object\u0026#39;\r\rDescribe data\rdf.describe()\r\rUnique vs Nunique\rfor col in df.columns: # for loop to get column names\rdf[col].unique() # returns unique values in column \u0026#39;col\u0026#39;\rdf[col].nunique() # returns unique values in column AND drop NAs\r\r\rSlicing and Filtering\rFilter\rdf.filter(items=, like=None)\r\rIloc \rdf.iloc[row_position, col_position] # general format\rCOPY of dataframe is slice is returned. This CANNOT be used in assignment. Also, note that only integers, its derivations and boolean arrays can be used to index.\r\rLoc\rindex = (df.Color==\u0026quot;Red\u0026quot;) \u0026amp; (df.Item==\u0026quot;Shirt\u0026quot;) # produces a boolean array\rdf.loc[index] # returns original dataframe sliced\rdf.loc[row_indexer, col_indexer] #general format\rNote: colon “:” is not needed by col_indexer like in df.loc[index, :] to choose all columns, and slice of ORIGINAL dataframe is returned. This can be used for assignment.\r\rQuery (columns)\rdf.query(\u0026#39;expression\u0026#39;) # expression must be conditional using column variable/s\r# prefix \u0026quot;@\u0026quot; before variable name if outside of dataframe env.\r# prefix ` ` to encapsulate variable name with spaces\rCan be used to filter rows.\r\r\rData Processing\rApply (a function on a pandas object)\rdf.apply(FUN, axis=0, *args) # FUN: any (valid) function to apply\r# axis: axis to assess\r# *args: additional keyword arguments for FUN\r\rAssign (new columns)\rdf.assign(col_4 = col_1*col_2/col_3)\rUsed to create new columns. Similar to “mutate” in R.\r\rGet Dummies (One Hot Encoding)\rdf.get_dummies(dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=np.uint8)\r# dummy_na: if True, adds dummy column for NA\r# columns: if !None, columns specified will be one hot encoded\r# sparse: whether resulting columns will be SparseArray objects (True) or NumPy arrays(False) # drop_first: removes first unique dummy variable from unique objects in column\r# dtype: data type for new columns (e.g. float)\rSeries.get_dummies(dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=\u0026#39;np.uint8\u0026#39;)\r\rGroup by, then Transform\rdf.groupby(by=category).transform(FUN)\r\rGrouping a dataframe then transforming it is a very common operation. A dataframe is converted into a “GroupBy” object depending on category, which may be a string or list of strings representing column names. Then the resulting object’s values are passed into FUN by the transform function and a column of the same size is returned.\n\r\rHandling NA\r#Finding NA and inverse\rdf.isna()\rSeries.isna()\rdf.notna()\rSeries.isna()\r#Dropping NA\rdf.dropna(axis=0, how=\u0026#39;any\u0026#39;, thresh=None, subset=None, inplace=False)\r# axis: axis to assess\r# how: when to drop axis (e.g. how=\u0026#39;all\u0026#39; drops IFF all values are NA)\r# thresh: number of NAs in axis to drop\r# subset: labels on axis to be considered\r# inplace: by default, returns new object. If True, modifies existing object\rSeries.dropna(axis=0, how=None,inplace=False)\r#Filling NA\rdf.fillna(value=None, method=None, axis=None, inplace=False, limit=None)\r# value: value to fill holes\r# method: method for filling holes.*\r# inplace: by default, returns new object. If True, modifies existing object\r# limit: max number of consecutive NAs to fill. Will be left as NA if value is exceeded\rSeries.fillna(value=None, method=None, axis=None, inplace=False, limit=None)\r\rMapping\rdf.applymap(FUN)\rSeries.map(FUN)\rIterates by rows (for Series) and cell (for DataFrame), passing cell value into function with the output value replacing its input value.\r\rPiping Data (through multiple functions)\rdf.pipe(FUN1).pipe(FUN2, arg1=foo).pipe((FUN3, \u0026quot;arg2\u0026quot;), arg1=bar) # when FUN3\u0026#39;s main arg. is not df, supply tuple\rwhere str contains location for df (e.g. \u0026quot;arg2\u0026quot;)\r)\rNOTE: similar to %\u0026gt;% operation in R.\r\rRolling\rdf.rolling(num_observations).FUN()\rSeries.rolling(num_observations).FUN()\r# Example of counting observations every 7 days past\rSeries.rolling(\u0026#39;7d\u0026#39;).count()-1 # subtraction excludes day \rThis is similar to GroupBy then Transform, but function is applied to “rolls” going down a specific column/index.\n\r\n\r\rAdditional Resources\rA great resource for comparing df.agg(), df.apply(), df.applymap() and df.transform() can be found here.\r\r\r","date":1594425600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"2d52eefdd8c099febfe6a0e9712f771b","permalink":"/post/pandas/useful_commands_to_remember/","publishdate":"2020-07-11T00:00:00Z","relpermalink":"/post/pandas/useful_commands_to_remember/","section":"post","summary":"Amassing a collection of useful Python Pandas library commands!","tags":["Python Libraries"],"title":"Save the Pandas...library","type":"post"},{"authors":[],"categories":["R"],"content":"\r\r.note{font-size: 10pt;\rline-height: 20pt;\rpadding-bottom: 10px}\rp{text-indent: 2em;}\rdetails{font-size: 10pt;}\rsummary{font-size: 100% !important;}\r\r\r\rTrying to simulate a random event? Then you’ve come to the right place!\r\r\r\rIf you do not have true proportion or estimated probabilities for your simulation, then this may not help you!\n\r\rPremise\rSay you want to understand how randomness works, and you want to roll a 12-sided die and see how many times it lands on 1. You’ll do roll a die 100, 10,000, 1,000,000 times.\nNote: Every side of the die has a probability of 1/12, but the outcome of each roll is random and independent from one another.\r\rStep 0: Set the seed to some arbitrary constant. (Optional)\rset.seed(2009, sample.kind=\u0026quot;Rounding\u0026quot;) #for R 3.6 and later\rset.seed(2009) #for 3.5 and older\rIf you wish to observe the same results for lower numbers of draws, you can place this at the start of your script.\r\rStep 1: Construct a method for sampling.\rNs = c(100, 10000, 1000000) #number of simulations\rsimulations \u0026lt;- sapply(Ns, function(N){\rsim \u0026lt;- sample(c(1, -1), N, replace=TRUE, prob=c(1/12, 11/12)) #sampling\rmean(sim == 1) #find the proportion of rolls which are 1 (success)\r})\r\r\rSample.Size\rProportion.Observed\r\r\r\r1e+02\r0.060000\r\r1e+04\r0.081600\r\r1e+06\r0.083332\r\r\r\rThe sample function takes N rolls (with replacement). The result can either be 1; a success (landing on 1), or -1; a failure (not landing on one). The keyword argument “prob” defines the probability for possible events success or failure.\nAs you can see from the results, the proportion of rolls landing on 1 converges to the probability we defined it to be (1/12 = 0.0833), as the number of rolls increases.\n\rFor Understanding\r\rTo close, it may be good to point out a common misconception when it comes to expectation. Say if you and your friends are tossing a coin and it lands on heads, you might be tempted to say “The next one will be tails!”, but that’s wrong. We know logically that the probability of either side landing is 1/2, but we would only be able to observe this when we sum up the results of maybe a thousand or hundred thousand rolls, as we have just done.\rThe Law of Large Numbers (or the Law of Averages) states that as the number of draws (rolls) increases, the standard error (standard deviation but for samples) of the expected value approaches 0. In which case, the expected value converges to the probability we defined.\r\rEnrichment\r\rYou can try to compute for the standard error for each simulation using the formula:\n\\(SE[\\overline{X}]=|b-a|*\\frac{\\sqrt{p(1-p)}}{N}\\)\nwhere SE means standard error;\nX_bar is the sample random variable;\na and b are the values we attribute to success and failure (i.e. 1 and -1);\np is the probability of success (i.e. 1/12);\nand N is the sample size.\r\r\nNOTE: For cases wherein the probability is not defined, we can use the replicate function that takes two arguments. The second argument defines a line or set of lines to replicate, while the first argument is the number of times you wish to repeat the second argument.\nExample: Creating a list of sample means.\narray # a non-empty numeric array of length 100,000\rB \u0026lt;- 1000 # number of replications\rN \u0026lt;- 100 # number of samples\rsample_means \u0026lt;- replicate(B, {\rsample_array \u0026lt;- sample(array, N, replace=TRUE)\rmean(sample_array) #like a function; this is returned\r})\r\r\r","date":1593820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594522504,"objectID":"ff9c185f89c790c3601884e1e08fbc15","permalink":"/post/monte-carlo-simulations/monte-carlo-simulations/","publishdate":"2020-07-04T00:00:00Z","relpermalink":"/post/monte-carlo-simulations/monte-carlo-simulations/","section":"post","summary":"After a bad roll, should you expect your luck to turn?","tags":["Modeling","Statistics and Probability"],"title":"Monte Carlo Simulations","type":"post"},{"authors":[],"categories":[],"content":"\r\rsummary h3{ display: inline-block;\rfont-size:20px;\rfont-family:\"Quicksand\";\rmargin-top: 0;\rmargin-bottom: 0;\r}\rh4{\rcolor: #45421D;\r}\rh5{\rdisplay: inline-block;\rcolor: black\r}\rp{font-size: 80%; text-indent: 2em;\rline-height: 0.5}\r\r\rUniversity of Toronto\r\r\r\rFoundations in Life Sciences\r\rCourses Taken: BIO120, BIO130, BIO230, BIO260, BCH210, BCH311\nDeveloped a good understanding of topics in molecular biology, genetics and biochemistry.\n\rFoundations in Computer Science\r\rCourses Taken: CSC108, CSC148, CSC165, CSC258\n\rFoundation in Statistical Sciences and Mathematics\r\rCourses Taken: MAT135, MAT136, MAT223, MAT235\n\rBasics of Cognitive Psychology\r\rCourses Taken: PSY100, PSY270\n\r\r\rGrades\r\r\r\r\r\rYear\rCourse.Code\rName\rGrade\r\r\r\r2\rBCH210\rBiochemistry I\rA-\r\r2\rBCH311\rBiochemistry II\rA+\r\r2\rBIO230\rFrom Genes to Organisms\rA+\r\r2\rBIO260\rGenetics\rA-\r\r2\rCSC148\rIntro to Computer Science\rA+\r\r2\rCSC165\rMathematical Expression and Reasoning for Computer Science\rA\r\r2\rMAT223\rLinear Algebra I\rA+\r\r2\rPSY270\rIntro to Cognitive Psychology\rCredited\r\r2\rSTA299\rResearch Opportunity Program\rA+\r\r1\rBIO120\rAdaptation and Biodiversity\rA\r\r1\rBIO130\rMolecular and Cell Biology\rA+\r\r1\rCHM135\rChemistry: Physical Principles\rA-\r\r1\rCHM136\rIntroductory Organic Chemistry I\rA-\r\r1\rCSC108\rIntroduction to Computer Programming\rA+\r\r1\rMAT135\rCalculus I\rA\r\r1\rMAT136\rCalculus II\rA-\r\r1\rIMM250\rThe Immune System and Infectious Disease\rA\r\r1\rNMC101\rLand of the Pharaohs\rB+\r\r1\rPSY101\rIntroductory Psychology\rA\r\r\r\r\r\r\r\rEdX\r\r\r\r\rHarvardX Data Science: R Basics\nHarvardX Data Science: Visualization\nHarvardX Data Science: Probability\nHarvardX Data Science: Inference and Modeling\nHarvardX Data Science: Productivity Tools\n\r\r\r\r\rKaggle Micro-courses\r\r\r\r\rIntro to Machine Learning\nIntermediate Machine Learning\nFeature Engineering\nDeep Learning\nIntro to SQL\n\r\r","date":1593816601,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593816601,"objectID":"1a76532d6ea387b255a790f767e744b0","permalink":"/courses/","publishdate":"2020-07-03T18:50:01-04:00","relpermalink":"/courses/","section":"","summary":"summary h3{ display: inline-block;\rfont-size:20px;\rfont-family:\"Quicksand\";\rmargin-top: 0;\rmargin-bottom: 0;\r}\rh4{\rcolor: #45421D;\r}\rh5{\rdisplay: inline-block;\rcolor: black\r}\rp{font-size: 80%; text-indent: 2em;\rline-height: 0.5}\r\r\rUniversity of Toronto\r\r\r\rFoundations in Life Sciences\r\rCourses Taken: BIO120, BIO130, BIO230, BIO260, BCH210, BCH311","tags":[],"title":"Courses Completed","type":"page"},{"authors":null,"categories":null,"content":"","date":1593648000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593648000,"objectID":"c9b5771543b03b8149b612b630936a56","permalink":"/experience/","publishdate":"2020-07-02T00:00:00Z","relpermalink":"/experience/","section":"","summary":"","tags":null,"title":"Experience","type":"widget_page"},{"authors":[],"categories":["Others"],"content":"\rHere lies my first blog post.\n","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"56667fe58b016d061a43b558957c66ec","permalink":"/post/first/a-first/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/post/first/a-first/","section":"post","summary":"One to set the record books","tags":null,"title":"A First","type":"post"},{"authors":["Stanley Z. Hua"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Stanley Z. Hua","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Stanley Z. Hua","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]